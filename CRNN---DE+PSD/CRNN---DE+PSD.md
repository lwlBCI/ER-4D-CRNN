### 论文简单叙述

:worried:由于难以选择高质量的数据、预处理方法和分类模型，基于脑图创建情感分类模型是一项具有挑战性的任务。本文的主要目的是构建一个进化模型，从作为输入的脑图中，人们可以在唤醒光谱和效价光谱中对情绪进行分类。为此，第一步是通过**差分熵（DE）和功率谱密度（PSD）创建脑图。**它们与电极位置的空间信息相结合，可以创建多个2D阵列作为建议方法的输入。**[基于该领域先前的工作](https://link.springer.com/article/10.1007/s11571-020-09634-1)**，输入通过一个CNN模型传递，选择该模型是因为它具有分析空间分布数据表示的能力和较高的计算效率。

:smirk:选定的特征在情绪检测和创建脑图方面具有重要意义。**脑电信号易受噪声影响，因此该特征必须提供有关信号的最佳信息，选定的就是PSD(功率谱密度)和DE（差分熵）**。(这是这篇论文对4D-CRNN进行改进的原因，就是加入了一个新的特征功率谱PSD)

:grin:我们遵循[先前工作中](https://link.springer.com/article/10.1007/s11571-020-09634-1)描述的方法，其中构建了4D特征结构，包括频率、空间和时间特征。基于所做的工作，原始脑电图信号被分割成T的长度段，没有重叠以增加数据量。然后将片段分解为alpha、beta、gamma和theta频带。已知大脑活动中有五种不同的波，范围从0赫兹到30赫兹以上，δ波属于0-4赫兹范围，通常在深度睡眠中观察到；它在清醒人群的情绪识别中不显著(**意思就是δ波不用**)。其他描述大脑从放松到高度活动或兴奋状态的波形通常用于使用脑电图信号的情绪识别。

:grinning:提取每个频带的DE和PSD来描述这些不同的波。PSD描述了信号中的功率，是频域中实现情感识别最常用的特征之一，DE测量信号的复杂性。然后，从原始脑电信号中提取每个频带的PSD和DE矢量，并将其转换为脑图，以保留电极位置的空间信息。如下图所示，脑图是在所有四个频带测量的PSD和DE的2D表示。对于每个0.5秒的窗口，所有波段和特征的脑图都会被创建并深度叠加。每个脑图都是模型的输入，高度h=8，宽度w=9，深度d=8。

![image-20230205104448541](https://cdn.jsdelivr.net/gh/lwlBCI/ER-4D-CRNN/images/image-20230205104448541.png)

:fire:与4D-CRNN不同的第一个点：其实说白了就是**在4D-CRNN模型的基础上加入了PSD结构层，由8*9*4变为了8*9*8,4个DE，4个PSD**

### 模型的改进

:yellow_heart:本研究使用了一种完全卷积的架构，**完全的卷积也就意味着只有CNN结构，没有RNN或者LSTM**，这是与4D-CRNN里面不同的第二个点因为它能够对类似图像的数据进行推理，并且这种架构的GPU学习过程高度优化。下图显示了提议的完全CNN多任务神经网络的总体结构。模型的输入是脑图，它是EEG信号的空间频谱表示。该模型由四个2D卷积层、一个完全连接层以及上述各层之后的Dropout和Batch Normalization层组成。最后，输出分为两个流：前者用于分类受试者效价(arousal)水平，后者用于唤醒(valence)。ReLU用作激活函数。分类层使用S形函数(softmax)来获得类似概率的输出。对模型进行了收敛训练。

![image-20230205104635784](https://cdn.jsdelivr.net/gh/lwlBCI/ER-4D-CRNN/images/image-20230205104635784.png)

:purple_heart:在训练过程中，只有特定对象的数据子集被用来最大限度地提高情绪识别的性能。众所周知，为了提高深度学习模型的泛化能力，需要大量的训练数据集。但是，由于EEG数据的跨学科可变性很高，使用**全套受试者进行训练会导致性能模型的退化(这就是为什么在大多数EEG解码的文章中，往往都是针对某一受试者进行训练和测试，而不是用所有受试者的数据)**，因此在本文的训练代码中，第一步首先是进行了all_subjects数据的训练，也就是153600 x 1 x 8 x 9 x 8条数据，分为训练集122880和30720全部进行训练然后验证。**第二步，是针对每位受试者，将第一步中全部数据训练的权重载入后，针对每位受试者的数据训练后进行微调，也就是说这样训练出来的模型针对的是每一个受试者，32位受试者也就是有32个微调后的模型**。第三步是针对两个情绪维度Valence和Arousal进行微调，同样的也是先载入所有的训练数据的权重，然后再利用每个情绪维度本身的数据微调。为了在训练过程中利用广泛的受试者，我们在研究中使用了人工神经网络的正则化方法，包括辍学、批量归一化和学习速率指数衰减。最终模型的性能定义通过五倍交叉验证方法进行。在每个分区中，122880张脑图被用作训练集，30720张作为测试集。模型采用反向传播方法进行训练。交叉熵损失被用作成本函数。使用多任务学习原理训练最终模型。(这地方所提到的权重载入进行微调的方法是[源代码](https://github.com/dolphin-in-a-coma/multi-task-cnn-eeg-emotion)中的方法，我个人并不太理解这种做法，尽管上面已经进行了原因的阐述。读者可以参考源代码进行理解和学习)

:blue_heart:**多任务学习是一种使用单个模型或其一部分来解决多个问题的方法。因此，一次解决不同的任务有利于模型泛化。 此外，这种方法允许在训练和推理过程中节省计算资源，因为在一个过程中，模型会同时针对多个任务进行训练。在这项研究中，我们要处理两个任务：对效价和唤醒水平进行分类。最终损失函数是原始损失函数的加权和，然后可以使用反向传播方法来解决问题。本文的多任务体现在利用同一的CNN架构来进行Arousal_classifier和Valence_classifier两个数据流的输出**，最后的总损失:

​                                                                                           :collision: 总loss=arousal_loss+valence_loss

### 如何使用

:star:关于我个人上传的代码使用方法与"4D-CRNN"的方法相同，都是先运行1D文件，再执行3D文件，最后执行训练文件

:star2:**值得注意的是：CRNN---DE+PSD的1D文件中多了生成PSD特征的函数，请读者在使用时仔细理解！**

### Cite

Rudakov E, Laurent L, Cousin V, et al. Multi-Task CNN model for emotion recognition from EEG Brain maps[C]//2021 4th International Conference on Bio-Engineering for Smart Technologies (BioSMART). IEEE, 2021: 1-4.

最后感谢[原作者](https://github.com/dolphin-in-a-coma)提供的思路与代码